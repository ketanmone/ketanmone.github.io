# üéì MSc Cyber Security ‚Äî Research Methods & Professional Practice

**Student:** Ketan Dileep Mone  
**Course:** University of Essex Online ‚Äî MSc Cyber Security  
**Module:** Research Methods & Professional Practice  
**Live URL:** [https://ketanmone.github.io/rmpp/](https://ketanmone.github.io/rmpp/)


---

This e-portfolio summarises learning and artefacts from **Units 1‚Äì12**, maps them to the module‚Äôs formative and summative requirements, and closes with a **Reflective synthesis** (Rolfe et al.‚Äôs What? / So What? / Now What?). I joined **two live seminars** and **engaged via recordings** for the remaining sessions, supplementing with extended reading and detailed write-ups to maintain continuity and depth.

---

## üß© Unit 1 ‚Äî Introduction to Research Methods: Scientific Investigation & Ethics in Computing

**Focus:** The scientific method; deductive vs. inductive reasoning; ethics and professionalism in computing.  
**Overview:** I revisited the **purpose of research**‚Äîto explore, describe, and explain (QuestionPro, 2021). Andersen & Hepburn (2020) framed the scientific method as observation ‚Üí hypothesis ‚Üí reasoning ‚Üí testing. I contrasted **deduction** (idea ‚Üí observation ‚Üí conclusion) with **induction** (observation ‚Üí analysis ‚Üí theory), noting where each is reliable. The **Menlo Report** principles‚Äîrespect, beneficence, justice, and respect for law/public interest‚Äîestablished an ethical anchor for design and data collection, complemented by the **BCS Code of Conduct** for professionalism.  
**Key Learnings:** Ethics is integral to research quality; deduction demands sound premises; induction supports real-world problems with partial information; professionalism (IP, data protection) shapes responsible practice.  
**Activities Completed:** Lecturecast; ~7 hrs reading; **Reasoning Quiz**; **Reflective Activity 1 ‚Äî Ethics in Computing in the age of Generative AI**; participation in **Collaborative Discussion 1**.  
**Reflection:** Treating ethics as a determinant of validity‚Äînot a compliance hurdle‚Äîimproves recruitment, honesty in responses, and public trust.

---

## üß© Unit 2 ‚Äî Research Questions, Literature Review & Proposal

**Focus:** From broad topic to researchable question; how to search, evaluate, and synthesise literature.  
**Overview:** Using Dawson (2015) and Boza (2022), I refined a broad interest‚Äî**IoT security and governance**‚Äîinto a focused, reviewable question. I documented **search strategy**, **inclusion/exclusion criteria**, and **bias-reduction** methods.  
**Key Learnings:** A strong question calibrates methodology; a rigorous literature review identifies gaps and theory/method choices; transparent search/selection logs support reproducibility.  
**Activities Completed:** Lecturecast; ~7 hrs reading; **e-Portfolio: Literature Review & Research Proposal Outlines**; peer responses in Discussion 1.  
**Reflection:** The discipline of scoping and criteria-setting reduced drift and kept later analysis aligned to aims.

---

## üß© Unit 3 ‚Äî Methodology & Research Methods

**Focus:** Research philosophy, research design, and the link between assumptions and method.  
**Overview:** I examined **ontology/epistemology/axiology** (Saunders, Lewis & Thornhill, 2023) and how they inform **exploratory** vs. **conclusive** design (BRM). I distinguished **qualitative**, **quantitative**, and **mixed methods**, planning data types and instruments accordingly.  
**Key Learnings:** Methodology precedes method; research design (strategy, sampling, analysis) must align with the question; **primary vs. secondary** data pathways require different permissions and ethics.  
**Activities Completed:** Lecturecast (Interviews & Survey Design intro); ~4 hrs reading; **Research Proposal Review** (e-portfolio); **Seminar 2: Peer Review Activity** (comparing two papers using different methods).  
**Reflection:** The ‚Äúresearch onion‚Äù helped me justify choices rather than assemble tools ad hoc; peer review sharpened critical appraisal.

---

## üß© Unit 4 ‚Äî Case Studies, Focus Groups & Observations

**Focus:** Qualitative data collection approaches and their trade-offs.  
**Overview:** I compared **case studies** (depth, contextual validity, limited generalisability), **focus groups** (exploratory insights, moderation bias), and **observations** (qualitative vs. quantitative modes). I learned to match method to the question, sampling frame, and validity aims.  
**Key Learnings:** Triangulation increases trustworthiness; choose roles in observation (complete observer ‚Üí full participant) carefully; pre-planning topic guides and consent improves data quality.  
**Activities Completed:** ~4 hrs reading; **Literature Review Outline submission** (formative); **Seminar 3: Case Study on Privacy**; reflective notes on method suitability for my IoT topic.  
**Reflection:** Qualitative methods surface mechanisms (‚Äúhow‚Äù and ‚Äúwhy‚Äù) that complement statistical patterns‚Äîparticularly vital in socio-technical security contexts.

---

## üß© Unit 5 ‚Äî Interviews, Survey Methods & Questionnaire Design

**Focus:** Designing interviews and surveys; understanding population vs. sample; pre/post testing.  
**Overview:** I learned the cycle from **questionnaire design** ‚Üí **logic** ‚Üí **distribution** ‚Üí **data collection** ‚Üí **analysis**, differentiating a **survey** (process) from a **questionnaire** (instrument). I planned **semi-structured interviews** and **online surveys**, balancing open/closed questions and avoiding leading/loaded phrasing.  
**Key Learnings:** Sampling frames determine external validity; piloting surfaces ambiguity; mixed question types capture both breadth and depth; pre/post testing shows intervention effects.  
**Activities Completed:** Lecturecast; ~4 hrs reading; **Reflective Activity 2 (surveys)**; **Wiki Activity: Questionnaires**; e-portfolio update on **data-collection plan** for my proposal.  
**Reflection:** The best surveys are short, unambiguous, and purposeful‚Äîdesigned backward from analysis needs.

---

## üß© Unit 6 ‚Äî Quantitative Methods: Descriptive Statistics

**Focus:** Levels of measurement; summary measures; early visual summaries.  
**Overview:** Guided by Berenson, Levine & Szabat (2020), I aligned **nominal/ordinal/interval/ratio** data with admissible statistics, calculated **location** (mean/median/mode) and **dispersion** (range/variance/SD/IQR), and sketched early **graphs**.  
**Key Learnings:** Respect measurement levels; prefer **effect sizes** and distributions to single-point claims; data cleaning and assumption checks precede inference.  
**Activities Completed:** ~4 hrs reading; seminar prep for Unit 7; worksheet planning.  
**Reflection:** Descriptive statistics are where integrity starts: **good summaries prevent bad inference**.

---

## üß© Unit 7 ‚Äî Inferential Statistics & Hypothesis Testing

**Focus:** Probability, sampling distributions, and hypothesis tests.  
**Overview:** Following Purdue (2023), I linked **samples to populations** through probability and conducted basic tests (e.g., t-tests, chi-square) where assumptions held. I learned to report **confidence intervals** and **effect sizes** alongside p-values.  
**Key Learnings:** Inference is uncertainty management; **assumptions matter** (normality, independence, homogeneity); choose tests to match designs and scales.  
**Activities Completed:** Lecturecast; **Compulsory e-Portfolio Worksheets** (Summary Measures & Hypothesis Testing); **Seminar 4: Inferential Statistics Workshop**; began **Collaborative Discussion 2**.  
**Assessment:** **Literature Review ‚Äî 70% (Distinction).**  
**Reflection:** Statistical literacy means knowing what to **not** infer; interpret patterns with discipline and humility.

---

## üß© Unit 8 ‚Äî Data Analysis & Visualisation

**Focus:** Qualitative coding; dashboard thinking; ethical visual communication.  
**Overview:** I contrasted **qualitative** and **quantitative** analysis pipelines. For qualitative data, I outlined **coding** (open ‚Üí axial ‚Üí selective) and use of tools for traceability. For visualisation, Microsoft (2023) and the **FT Visual Vocabulary** emphasised aligning chart type to question‚Äîpart-to-whole, correlation, distribution, ranking, change, etc.  
**Key Learnings:** Start analysis with a **display purpose** in mind; label axes, cite sources, show uncertainty; avoid chartjunk; dashboards link metrics to **decisions**.  
**Activities Completed:** ~7 hrs reading; **Charts Worksheet** (e-portfolio); **Inference Worksheet**; **Seminar 5: Workshop on Presenting Results**; **Research Proposal Outline** (formative).  
**Reflection:** Visualisation is rhetoric with numbers‚Äîclarity and honesty are ethical duties.

---

## üß© Unit 9 ‚Äî Validity, Reliability & Generalisability

**Focus:** Internal/external validity; construct validity; reliability; data preparation.  
**Overview:** I planned **pilot testing**, **inter-rater reliability** (qualitative), and instrument checks. I reviewed **cleansing/validation** steps before analysis to protect inference downstream.  
**Key Learnings:** Reliability is necessary but not sufficient‚Äî**validity** asks whether we measured the right thing; design decisions (sampling, timing) determine generalisability.  
**Activities Completed:** Lecturecast; **Charts Example Worksheet** (e-portfolio); **Discussion 2 Summary Post**; **Seminar** participation.  
**Reflection:** Build validity into design rather than trying to ‚Äúrepair‚Äù it later.

---

## üß© Unit 10 ‚Äî Research Writing

**Focus:** Communicating research as a coherent argument; proposal structure; publication mindset.  
**Overview:** I mapped the **proposal** into rationale, objectives, literature logic, methodology, data/analysis plan, ethics, limitations, and timeline‚Äîfollowing Dawson (2015). I practised writing sections as **connected claims** supported by evidence, not isolated parts.  
**Key Learnings:** Research writing is structured storytelling; signposting and cohesion matter; tone should be precise, economical, and transparent about uncertainty.  
**Activities Completed:** Lecturecast; ~4 hrs reading; **Statistical Worksheets submitted for feedback**; **proposal slide-deck with narration**.  
**Assessment:** **Research Proposal Presentation ‚Äî 67% (Merit)**.  
**Reflection:** Writing clarified thinking; explicit limitations increased credibility with reviewers.

---

## üß© Unit 11 ‚Äî Professional Development & the e-Portfolio

**Focus:** Consolidating evidence; skills matrix; CPD action planning.  
**Overview:** I curated artefacts, mapped learning outcomes, and drafted a **skills matrix** (research ethics, qualitative analysis, statistics, visualisation, academic writing). I planned CPD around **NVivo coding**, **power analysis/statistical modelling**, and **responsible AI** practice.  
**Key Learnings:** An e-portfolio is a **living record** for employability; reflective cadence improves method choice mid-project, not just at the end.  
**Activities Completed:** Reading on e-portfolio value; **Seminar 6: e-Portfolio Preparation**; final tidy-up of artefacts and references.  
**Reflection:** The e-portfolio is not storage; it is **curation and argument**.

---

## üß© Unit 12 ‚Äî Project Management & Managing Risk

**Focus:** Project life cycles; change and risk control; metrics and uncertainty.  
**Overview:** I reviewed **PMBOK 7e**, APM guidance, and agile/hybrid delivery. I set up a **risk log** (threats/opportunities), **change-control process**, and basic **Gantt** planning‚Äîlinking research milestones to dependencies and buffers.  
**Key Learnings:** No project is risk-free; measure what matters, inspect frequently, and keep change controlled; integrate research **governance** with delivery governance.  
**Activities Completed:** Reading on PM and uncertainty; **Self-Test Quiz**; finalisation of submission set.  
**Reflection:** Good research is good project management‚Äîscope clarity, iteration, documented decisions, and visible risks.

---

## üìÑ Appendix: Module Assignments & Artefacts

### üß† Literature Review (70% Distinction)  
**Title:** *Cybersecurity Threats in IoT: Towards Secure, Ethical, and Resilient Frameworks*  
**Type:** Individual report (PDF)  
**Date:** 15th September 2025  
**File:** [Cybersecurity_Threats_in_IoT_Towards_Secure_Ethical_and_Resilient_Frameworks.pdf](https://ketanmone.github.io/assets/rmpp/docs/Cybersecurity_Threats_in_IoT_Towards_Secure_Ethical_and_Resilient_Frameworks.pdf)  
**Overview:** A structured synthesis of IoT security literature across technical controls (identity, segmentation, update hygiene), **ethical governance**, and resilience.  
**Key Outcomes:** Clear gap-analysis; method-aware critique; directions for mixed-methods research.

### üß© Research Proposal Presentation (67% Merit)  
**Title:** *Mixed-Methods Study of IoT Governance in Smart Cities*  
**Type:** Slide deck + audio narration (MP4)  
**Date:** 6th October 2025  

<video width="720" height="405" controls>
  <source src="https://ketanmone.github.io/rmpp/Research_Proposal_Presentation_Ketan_Mone.mp4" type="video/mp4">
</video> 
**Overview:** Problem definition, review logic, methodology (convergent mixed-methods), ethics (Menlo + BCS), data/analysis plan, and timeline.  
**Key Outcomes:** Methodological coherence; ethical safeguards; feasible schedule and risk plan. 

### üìò Summary Measures
**Artifact:** [Summary_Measures_Worksheet.pdf](https://ketanmone.github.io/rmpp/Summary_Measures_Worksheet.pdf) 
This worksheet analyses measures of central tendency (mean, median, mode) and dispersion (range, variance, standard deviation, IQR) for two diet programmes.  
**Key insights:** Diet A exhibits higher mean weight loss and lower variability, confirming greater consistency. Brand frequency tables further highlight distinct area-based consumer patterns. 

### üìó Hypothesis Testing and Summary Measures
**Artifact:** [Hypothesis_Testing_Worksheet.pdf](https://ketanmone.github.io/rmpp/Hypothesis_Testing_Worksheet.pdf) 
Applies both **paired** and **independent samples t-tests** with preliminary F-tests for variance equality.  
**Findings:**  
- Significant mean difference between container designs (p ‚âà 0.018).  
- Diet A yields significantly higher mean weight loss than Diet B (p < 0.01).  
These results validate prior descriptive analysis and illustrate correct hypothesis formulation, directional testing, and interpretation.

### üìô Bar Charts and Histograms
**Artifact:** [Charts_Example_Worksheet.pdf](https://ketanmone.github.io/rmpp/Charts_Example_Worksheet.pdf) 
Visualises categorical and continuous data through percentage bar charts and relative-frequency histograms.  
**Findings:**  
- Brand preference charts show higher loyalty to named brands in Area 2.  
- Diet A‚Äôs histogram is nearly symmetric and consistent, while Diet B is right-skewed and variable.  
Both Excel and LibreOffice outputs confirm the reproducibility of statistical visuals.
---

## üßæ Reflective Synthesis

**File:** [Reflective_Synthesis_Research_Methods_Professional_Practice.pdf](https://ketanmone.github.io/rmpp/Reflective_Synthesis_Research_Methods_Professional_Practice.pdf)  
This final reflection uses Rolfe et al.‚Äôs (2001) model to evidence growth in **methodological reasoning**, **ethical awareness**, **statistical literacy**, **qualitative rigour**, and **research communication**. It identifies transfer to practice (governance, responsible AI, stakeholder engagement) and a concrete plan for the dissertation (mixed-methods IoT governance).

---

## üìö References

- Andersen, H. & Hepburn, B. (2020). *Scientific Method*. Stanford Encyclopedia of Philosophy.  
- Berenson, L., Levine, D. & Szabat, K. (2020). *Basic Business Statistics* (14th ed.). Pearson.  
- BCS (2021). *Code of Conduct*.  
- Boza, T. (2022). *How to Write a Literature Review*.  
- BRM (n.d.). *Research Design*; BRM (2021). *Qualitative Data Analysis*.  
- Dawson, C. (2015). *Projects in Computing and Information Systems* (3rd ed.). Pearson.  
- Microsoft (2023). *Why data dashboards are important*.  
- Purdue University (2023). *Basic Inferential Statistics*.  
- Saunders, M., Lewis, P. & Thornhill, A. (2023). *Research Methods for Business Students* (9th ed.). Pearson.
- Field, A. (2018) Discovering Statistics Using IBM SPSS Statistics. 5th edn. London: SAGE Publications.
- Upton, G. and Cook, I. (2014) Oxford Dictionary of Statistics. 3rd edn. Oxford: Oxford University Press.


---

[üè† Home](./) | [üîó GitHub Repository](https://github.com/ketanmone/ketanmone.github.io)
